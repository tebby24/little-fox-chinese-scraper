{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "GENERIC_XML_URL = \"https://cdn.littlefox.co.kr/cn/captionxml/C0001143.xml\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series Class Definition\n",
    "Represents a single series on LFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class Series:\n",
    "    def __init__(self, series_title, series_id):\n",
    "        \"\"\"\n",
    "        Initialize the Series class with the given series ID.\n",
    "        \n",
    "        :param series_id: The ID of the series.\n",
    "        \"\"\"\n",
    "        self.main_url = f'https://chinese.littlefox.com/en/story/contents_list/{series_id}'\n",
    "\n",
    "    def get_page_count(self):\n",
    "        \"\"\"\n",
    "        Get the total number of pages for the series.\n",
    "        \n",
    "        :return: The maximum page number or None if not found.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = requests.get(self.main_url)\n",
    "            response.raise_for_status()\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching main URL: {e}\")\n",
    "            return None\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        paging_div = soup.find('div', class_='lf_paging')\n",
    "\n",
    "        if paging_div:\n",
    "            page_numbers = [\n",
    "                int(a_tag.text) for a_tag in paging_div.find_all('a') if a_tag.text.isdigit()\n",
    "            ]\n",
    "            if page_numbers:\n",
    "                return max(page_numbers)\n",
    "        return None\n",
    "\n",
    "    def get_page_urls(self):\n",
    "        \"\"\"\n",
    "        Generate a list of URLs for all pages in the series.\n",
    "        \n",
    "        :return: A list of page URLs or None if no pages are found.\n",
    "        \"\"\"\n",
    "        max_page_count = self.get_page_count()\n",
    "        if max_page_count:\n",
    "            return [f'{self.main_url}?&page={page}' for page in range(1, max_page_count + 1)]\n",
    "        else:\n",
    "            print(\"No pages found\")\n",
    "            return None\n",
    "\n",
    "    def get_ep_ids(self):\n",
    "        \"\"\"\n",
    "        Extract episode IDs from all pages in the series.\n",
    "        \n",
    "        :return: A list of episode IDs.\n",
    "        \"\"\"\n",
    "        page_urls = self.get_page_urls()\n",
    "        if not page_urls:\n",
    "            return []\n",
    "\n",
    "        ids = []\n",
    "        for url in page_urls:\n",
    "            try:\n",
    "                response = requests.get(url)\n",
    "                response.raise_for_status()\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"Error fetching page URL {url}: {e}\")\n",
    "                continue\n",
    "\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            items = soup.find_all('div', class_='item')\n",
    "            ids.extend(\n",
    "                input_element.get('value')\n",
    "                for item in items\n",
    "                if (input_element := item.find('input', class_='LF_CHK s2 contentsCheck'))\n",
    "            )\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_stories_1 = Series('DP000732')\n",
    "len(single_stories_1.get_ep_ids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series Extraction\n",
    "Extract the series title and id from the homepage.\n",
    "Since the first 6 series do not have subtitles, they will be ignored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-smid: DP000777, title: Nihao Chinese!\n",
      "data-smid: DP000778, title: Introduction to Tones\n",
      "data-smid: DP000779, title: Introduction to Simple Finals\n",
      "data-smid: DP000780, title: Introduction to Initials\n",
      "data-smid: DP000782, title: Introduction to Compound Finals\n",
      "data-smid: DP000781, title: Tone Change Rules\n",
      "data-smid: DP000732, title: Single Stories\n",
      "data-smid: DP000733, title: Mrs. Kelly's Class\n",
      "data-smid: DP000791, title: Who Am I?\n",
      "data-smid: DP000783, title: Where Am I?\n",
      "data-smid: DP000740, title: The Big Green Forest\n",
      "data-smid: DP000742, title: Bat and Friends\n",
      "data-smid: DP000792, title: Car School\n",
      "data-smid: DP000796, title: Dino Buddies\n",
      "data-smid: DP000738, title: Single Stories\n",
      "data-smid: DP000799, title: Space Patrol\n",
      "data-smid: DP000794, title: Peter Rabbit and Friends\n",
      "data-smid: DP000739, title: Wacky Ricky \n",
      "data-smid: DP000751, title: Magic Marker\n",
      "data-smid: DP000750, title: Bird and Kip\n",
      "data-smid: DP000737, title: Sam and Lucky \n",
      "data-smid: DP000746, title: Meet the Animals\n",
      "data-smid: DP000743, title: Single Stories\n",
      "data-smid: DP000805, title: Jack and the Beanstalk\n",
      "data-smid: DP000802, title: Puss in Boots\n",
      "data-smid: DP000803, title: Snow White and the Seven Dwarfs \n",
      "data-smid: DP000798, title: Cinderella\n",
      "data-smid: DP000762, title: Hana's Album\n",
      "data-smid: DP000745, title: Sunshine School\n",
      "data-smid: DP000793, title: Wizard and Cat \n",
      "data-smid: DP000760, title: The Carter Family\n",
      "data-smid: DP000752, title: Single Stories\n",
      "data-smid: DP000753, title: Fun at Kids Central\n",
      "data-smid: DP000804, title:  The Light Princess\n",
      "data-smid: DP000775, title: Rocket Girl\n",
      "data-smid: DP000755, title: Danny's Adventures\n",
      "data-smid: DP000747, title: The Wishing Well\n",
      "data-smid: DP000754, title: Thumbelina\n",
      "data-smid: DP000763, title: Single Stories\n",
      "data-smid: DP000806, title: Rocket Girl's Journey to the West\n",
      "data-smid: DP000756, title: Journey to the West\n",
      "data-smid: DP000801, title: Alice's Adventures in Wonderland\n",
      "data-smid: DP000797, title: The Jungle Book\n",
      "data-smid: DP000767, title: The Railway Children\n",
      "data-smid: DP000764, title: The Willow Creek Twins\n",
      "data-smid: DP000758, title: The Little Mermaid\n",
      "data-smid: DP000766, title: Aladdin and His Wonderful Lamp\n",
      "data-smid: DP000776, title: Pinocchio\n"
     ]
    }
   ],
   "source": [
    "homepage_url = 'https://chinese.littlefox.com/en/story'\n",
    "try:\n",
    "    response = requests.get(homepage_url)\n",
    "    response.raise_for_status()\n",
    "except requests.RequestException as e:\n",
    "    print(f\"Error fetching main URL: {e}\")\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "contents_divs = soup.find_all('div', class_='constents_wrap')\n",
    "series = []\n",
    "\n",
    "for div in contents_divs[6:]:\n",
    "    id = div['data-smid']\n",
    "    title = div.find('div', class_='thumb_titl').find('a').text\n",
    "    print(title)\n",
    "    series.append(Series(title, id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
